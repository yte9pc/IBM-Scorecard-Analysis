---
title: "Employee Attrition"
output: html_notebook
urlcolor: blue
author: Jon Gomez (jag2j), Michael Langmayr, Nathan England, and Yihnew Eshetu
---


# About the data

We will analyze the "IBM HR Analytics Employee Attrition & Performance" dataset ((link)[https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset]).  The dataset documentation says that it was synthesized by data scientists at IBM.  Observations describe hypothetical employees.  Rows measure the employee retention status, metrics about the workplace, and details about the employee.

# Preparation

## Libraries

```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(leaps))     # model selection tools
suppressPackageStartupMessages(library(faraway))   # VIF function

source('./lib/fmrhs.R') # requires tidyverse
source('./lib/Pretty correlation.R')
```

## Loading the data
We load the data using a custom column mapping.  A few considerations apply:

* Several columns are are originally numeric levels.  We recode these from the data description.
* A few columns are irrelevant or constant across the data.  We drop these.

```{r}

# column mappings
types = cols(
  # continuous variables
  Age = col_double(),              DailyRate = col_double(),  
  DistanceFromHome = col_double(), HourlyRate = col_double(),       
  JobLevel = col_factor(1:5),
  
  # ordered factors we later recode
  #   e.g., JobSatisfaction ranges from 1 - 4 (= 'Low' to 'Very High')
  Education                = col_factor(levels = 1:5),
  EnvironmentSatisfaction  = col_factor(1:4),
  JobInvolvement           = col_factor(1:4),
  JobSatisfaction          = col_factor(levels = 1:4),
  PerformanceRating        = col_factor(levels = 1:4),
  RelationshipSatisfaction = col_factor(levels = 1:4),
  WorkLifeBalance          = col_factor(levels = 1:4),
  
  # other factors
  BusinessTravel =  col_factor(levels = c('Non-Travel', 'Travel_Rarely', 'Travel_Frequently')),
  Gender = col_factor(),            JobRole = col_factor(),
  MaritalStatus = col_factor(),     EducationField = col_factor(),
  
  # things we have decided to treat as factors
  Department = col_factor(),        # we presume we could map to a taxonomy
  StockOptionLevel = col_factor(),  # unclear scale
  
  # true/false
  Attrition = col_factor(),
  OverTime = col_factor(),
  
  # drop
  EmployeeCount = col_skip(),  # always 1
  StandardHours = col_skip(),  # always 40
  EmployeeNumber = col_skip(), # 1, 2, ...
  Over18 = col_skip(),         # always true
  
  # continous values
  MonthlyIncome = col_double(),       MonthlyRate = col_double(),              
  NumCompaniesWorked = col_double(),  PercentSalaryHike = col_double(),
  TotalWorkingYears = col_double(),   TrainingTimesLastYear = col_double(),
  WorkLifeBalance = col_double(),     YearsAtCompany = col_double(),           
  YearsInCurrentRole = col_double(),  YearsSinceLastPromotion = col_double(),
  YearsWithCurrManager = col_double()
)

# read in using mapping
ibm = read_csv("data/ibm.csv", col_types = types)

# rename levels
ibm$Education = recode(ibm$Education, 
                       '1' = 'Below College', '2' = 'College', '3' = 'Bachelor', '4' = 'Master', '5' = 'Doctor')
ibm$EnvironmentSatisfaction = recode(ibm$EnvironmentSatisfaction, 
                       '1' = 'Low', '2' = 'Medium', '3' = 'High', '4' = 'Very High')
ibm$JobInvolvement = recode(ibm$JobInvolvement, 
                       '1' = 'Low', '2' = 'Medium', '3' = 'High', '4' = 'Very High')
ibm$JobSatisfaction = recode(ibm$JobSatisfaction, 
                       '1' = 'Low', '2' = 'Medium', '3' = 'High', '4' = 'Very High')
ibm$PerformanceRating = recode(ibm$PerformanceRating, 
                       '1' = 'Low', '2' = 'Good', '3' = 'Excellent', '4' = 'Outstanding')
ibm$RelationshipSatisfaction = recode(ibm$RelationshipSatisfaction, 
                       '1' = 'Low', '2' = 'Medium', '3' = 'High', '4' = 'Very High')
ibm$WorkLifeBalance = recode(ibm$WorkLifeBalance, 
                       '1' = 'Bad', '2' = 'Good', '3' = 'Better', '4' = 'Best')

# set contrasts for yes/no levels
ibm$Attrition = relevel(ibm$Attrition, ref = "No")
ibm$OverTime = relevel(ibm$OverTime, ref = "No")

```

## Additional data manipulations

We produce a defactored version of the data for which we have replaced factors with numeric vectors.
```{r}
ibm.defactored = mutate_if(ibm, is.factor, ~ as.numeric(.x))
```

## Sample observations

We show some sample data:
```{r}
# a sample observation
t(head(ibm, n = 1))
```

```{r}
head(ibm, n = 10)[,c(1:5)]
```

# General Observations

There are 1,470 rows and 31 columns.  

```{r}

```




```{r}
par(mfrow=c(2,2))
plot(ibm$EducationField)
plot(ibm$JobInvolvement)
plot(ibm$Education)
with(ibm, hist(Age))
```

```{r}

```

```{r}
summary(ibm)
```

## Correlation

We look at columns for which the correlation is greater than 70 in the defactored data:
```{r}
p = round(cor(ibm.defactored) * 100)
for(i in 1:nrow(p)) {
  for(j in i:ncol(p)) {
    if(i == j) next
    val = p[i,j]
    if(abs(val) > 70) {
      r = row.names(p)[i]
      c = colnames(p)[j]
      str = paste("cor(", r, ", ", c, ") = ", val, "\n")
      cat(str)
    }
  }
}
```


We also examine the VIFs of the defactored data for general interest.  We perform a formal test when we investigate specific models.
```{r}
model.defactored = lm(MonthlyIncome ~ ., data = ibm.defactored)
model.defactored.vifs = faraway::vif(model.defactored)

# Five highest VIFs with this "defactored" model on Monthly income
# 
model.defactored.vifs[order(model.defactored.vifs, decreasing = T)][1:5]
```



# Question 1

Our first question is

> What factors correlate with attrition?

```{r}
library(MASS)
null.model <- glm(Attrition ~ 1, family = "binomial", data = ibm)
full.model <- glm(Attrition ~ ., family = "binomial", data = ibm)
```
```{r}
#Forward selection model
forward_model <- null.model %>% stepAIC(trace = FALSE, direction = "forward")
summary(forward_model)
coef(forward_model)
```
```{r}
#Backward elimination model
backward_model <- full.model %>% stepAIC(trace = FALSE, direction = "backward")
summary(backward_model)
coef(backward_model)
backward_model$anova
```
```{r}
#Stepwise regression model using full
step_model <- full.model %>% stepAIC(trace = FALSE, direction = "both")
#summary(step_model)
#coef(step_model)
step_model$anova
```
```{r}
#Check multicollinearity
step_doubles <- step_model$model[, sapply(step_model$model, is.double) ]
faraway::vif(step_doubles)
```

```{r}
#Stepwise regression model with BIC
bic_model <- full.model %>% stepAIC(trace = FALSE, direction = "both", k = log(nrow(ibm)) )
#summary(step_model)
#coef(step_model)
bic_model$anova
```

```{r}
#Check multicollinearity
bic_doubles <- bic_model$model[, sapply(bic_model$model, is.double) ]
faraway::vif(bic_doubles)
```


```{r}
set.seed(199)

##split data into two equal parts
sample<-sample.int(nrow(ibm), floor(.50*nrow(ibm)), replace = F)
train<-ibm[sample, ]
test<-ibm[-sample, ]

##fit model using training data
aic_train<-glm(Attrition ~ Age + BusinessTravel + DailyRate + DistanceFromHome + 
    EducationField + EnvironmentSatisfaction + Gender + JobInvolvement + 
    JobLevel + JobRole + JobSatisfaction + NumCompaniesWorked + 
    OverTime + RelationshipSatisfaction + StockOptionLevel + 
    TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + 
    YearsAtCompany + YearsInCurrentRole + YearsSinceLastPromotion + 
    YearsWithCurrManager, family="binomial", data=train)

bic_train<-glm(Attrition ~ Age + BusinessTravel + Department + DistanceFromHome + 
    EnvironmentSatisfaction + JobInvolvement + JobLevel + JobSatisfaction + 
    NumCompaniesWorked + OverTime + StockOptionLevel + YearsInCurrentRole + 
    YearsSinceLastPromotion, family="binomial", data=train)

library(ROCR)
##predicted attrition rate for testing data based on training data
aic_preds<-predict(aic_train,newdata=test, type="response")
aic_preds

bic_preds<-predict(bic_train,newdata=test, type="response")
bic_preds

##produce the numbers associated with classification table
aic_rates<-prediction(aic_preds, test$Attrition)
aic_rates

bic_rates<-prediction(bic_preds, test$Attrition)
bic_rates

##store the true positive and false postive rates
aic_roc<-performance(aic_rates,measure="tpr", x.measure="fpr")
bic_roc<-performance(bic_rates,measure="tpr", x.measure="fpr")
##plot ROC curve and overlay the diagonal line for random guessing
plot(aic_roc, main="ROC Curve", col = "red")
plot(bic_roc, add = TRUE, col = "blue")
lines(x = c(0,1), y = c(0,1), col="black")
legend(0, 1, legend=c("AIC Step Model", "BIC Step Model"),
       col=c("red", "blue"), lty=1:2, cex=0.5)
```
```{r}
##compute the AUC
aic_auc<-performance(aic_rates, measure = "auc")
aic_auc

bic_auc<-performance(bic_rates, measure = "auc")
bic_auc
```
```{r}
##confusion matrix. Actual values in the rows, predicted classification in cols
table(test$Attrition, aic_preds>0.5)
table(test$Attrition, bic_preds>0.5)

hist(aic_preds)
hist(bic_preds) 
```
